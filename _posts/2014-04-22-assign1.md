---
layout: post
title: Assignment Iâ€”Image and Signal Processing
---
This is the writeup for the first assignment of `CSE 190`. 
I implement all of the techniques except convolution in frequency domain and compositing. 
The mathematics is not complex in this project, most of the work is completed by 
manipulating either pixel value or pixel coordinate directly. Therefore, I will mainly post up
outcomes without mentioning implementing details which are already well written in the assignment instruction.

 
## Basic Operations

### Brighten

Brighten flower.bmp with factor: **0.0,0.5,1.0,1.5,2.0**

 <img src="../img/bri0.bmp" /> | <img src="../img/bri0.5.bmp" /> | <img src="../img/bri1.bmp" /> | <img src="../img/bri1.5.bmp" /> | <img src="../img/bri2.bmp" /> | 
:-:|:-:|:-:|:-:|:-:
0.0|0.5|1.0|1.5|2.0        

For negative factor, it will return:
{% highlight cpp%}
The factor should be non-negative
{% endhighlight %} 

### Change Contrast

Change Contrast of flower.bmp with factor: **-0.5,0.0,0.5,1.0,1.7** 

 <img src="../img/contr-0.5.bmp" /> | <img src="../img/contr0.0.bmp" /> | <img src="../img/contr0.5.bmp" /> | <img src="../img/contr1.0.bmp" /> | <img src="../img/contr1.7.bmp" /> | 
:--:|:-:|:-:|:-:|:-:
-0.5|0.0|0.5|1.0|1.7  

### Change Saturation

Change Saturation of flower.bmp with factor: **-1.0,0.0,0.5,1.0,2.5** 

 <img src="../img/satur-1.0.bmp" /> | <img src="../img/satur0.0.bmp" /> | <img src="../img/satur0.5.bmp" /> | <img src="../img/satur1.0.bmp" /> | <img src="../img/satur2.5.bmp" /> | 
:--:|:-:|:-:|:-:|:-:
-1.0|0.0|0.5|1.0|2.5 


### Change Gamma

Change Gamma of flower.bmp with factor: **0.5,1.0,1.5,2.0** 

 <img src="../img/gam0.5.bmp" /> | <img src="../img/gam1.0.bmp" /> | <img src="../img/gam1.5.bmp" /> | <img src="../img/gam2.0.bmp" /> 
 :--:|:-:|:-:|:-:|:-:
0.5|1.0|1.5|2.0


For negative or zero factor, it will return:
{% highlight cpp%}
The factor should be positive
{% endhighlight %} 

### Crop

Crop flower.bmp with factor:**(x,y,w,h)=(50,30,80,80)**

<img src="../img/crop.bmp" style="display:inline"/>

If the location (x,y,x+w,y+h) is not valid, it will return:
{% highlight cpp%}
The corner location is not valid
{% endhighlight %} 

If either w or h is less than zero, it will return:
{% highlight cpp%}
Width and height should be positive
{% endhighlight %} 

## Quantization and Dithering

Results can be compared with the table below. Here are three points I need to mention:

Firstly, as we know, `FloydSteinbergDither` is a little annoying in that we have to handle potential decimal and negative pixel value. For this problem, I pick out the whole calculation part into a single function, which is `Pixel` in `Pixel` out but process all of the data as float type inside the function.
{% highlight cpp%}
Pixel FloydSteinOperator (const Pixel& w, const Pixel& p, const Pixel& q, double t);
{% endhighlight %} 

Moreover, handling boundaries' pixels is another problem for `FloydSteinbergDither`. Honestly, I don't care much about these boundaries pixels in my former image processing work. I used to fill zeros or mirror symmetry values around the boundaries. In this project, I try both of the methods mentioned in the assignment instruction: `renormalization` and `toroidal extension`. I won't post up all of the outcome created by these two methods. The only difference lies on the 
boundaries which can barely be discriminated. In my source code, you can change method with the variable `solution`. 
As `toroidal extension` is easier to implement and expend to other cases. I write a separate function for it:
{% highlight cpp%}
Image* Image::Expand(int n);
{% endhighlight %} 

In addition, I try non-linear mapping in quantization. I use a mapping function like gamma correctness:
{% highlight cpp %}
q = floor(p/256*b)
w = pow(q/b,factor)
c = floor(255*b*w/(b-1))
{% endhighlight %}
It is controlled by the variable `solution`.

### Results:

\#Bits|1 | 2 | 3 | 4 | 5 |
 :--:|:-:|:-:|:-:|:-:|:-:|
Quan(L)|<img src="../img/quan1.bmp" /> |<img src="../img/quan2.bmp" />|<img src="../img/quan3.bmp" />|<img src="../img/quan4.bmp" />|<img src="../img/quan5.bmp" />
Random|<img src="../img/rand1.bmp" /> |<img src="../img/rand2.bmp" />|<img src="../img/rand3.bmp" />|<img src="../img/rand4.bmp" />|<img src="../img/rand5.bmp" />
FS|<img src="../img/floyd1.bmp" /> |<img src="../img/floyd2.bmp" />|<img src="../img/floyd3.bmp" />|<img src="../img/floyd4.bmp" />|<img src="../img/floyd5.bmp" />
Quan(NL)|<img src="../img/quann1.bmp" /> |<img src="../img/quann2.bmp" />|<img src="../img/quann3.bmp" />|<img src="../img/quann4.bmp" />|<img src="../img/quann5.bmp" />


> Quan(L): Normal Quantization   
Random: Random Dither   
FS: FloydSteinberg Dither   
Quan(NL): non-linear Quantization  

 

## Basic Convolution and Edge Detection

I implement an auxiliary Convolve function for this section.
{% highlight cpp%}
void Image::Convolve(int *filter, int n, int normalization, int absval);
{% endhighlight %} 
For solving the potential problem of negative pixel value, I implement a new class named iPixel(in `iPixel.h` and `iPixel.cpp`)
for storing and calculating `int` value pixels. Also, I use `toroidal extension` to handle the boundaries. Therefore, I do convolution as following procedure: 

	1. Extend the Source Image
	2. Loop for every pixel
	3. Turn Pixel into iPixel
	4. Calculate 
	5. Turn iPixel into Pixel
	
### Blur

Blur mandrill.bmp, firstly turn `float` Gaussian filter into `int` filter. 
With size of: **3,5,7,11,13** , I get:

 <img src="../img/blur3.bmp" /> | <img src="../img/blur5.bmp" /> | <img src="../img/blur7.bmp" /> | <img src="../img/blur11.bmp" /> | <img src="../img/blur13.bmp" />
 :--:|:-:|:-:|:-:|:-:
3|5|7|11|13


For valid input, it will return:
{% highlight cpp%}
Filter size n should be an odd integer
{% endhighlight %} 

### Sharpen

Using the filter given in assignment instruction, I sharpen mandrill image blurred by 13*13 Gaussian filter.

With sharpen times from **1 to 5**:

 <img src="../img/sharp1.bmp" /> | <img src="../img/sharp2.bmp" /> | <img src="../img/sharp3.bmp" /> | <img src="../img/sharp4.bmp" /> | <img src="../img/sharp5.bmp" />
 :--:|:-:|:-:|:-:|:-:
1|2|3|4|5

### Edge Detection

Using Sobel filter to detect edges:

checkerboard.bmp and checkerboard2.bmp have very "strict" edge, they are robust to different thresholds:

<img src="../img/check1.bmp" width="40%" height="40%" style="display:inline"/>
<img src="../img/check2.bmp" width="40%" height="40%" style="display:inline"/>

For wave.bmp, I try threshold from 50 to 250:

 <img src="../img/wave50.bmp" /> | <img src="../img/wave100.bmp" /> | <img src="../img/wave150.bmp" /> | <img src="../img/wave200.bmp" /> | <img src="../img/wave250.bmp" />
 :--:|:-:|:-:|:-:|:-:
50|100|150|200|250

As shown above, we can get satisfying edges with threshold around 200.


## Antialiased Scale and Shift

I give up the auxiliary Convolve function in this section. 
Instead, I implement all of techniques with two or more 1D processing. Fortunately, the coordinates of every pixel
required in the source image for calculating the goal image can be known with a simple close-form solution.
It is unnecessary to search every satisfying pixels with global loop.

For solving the potential problem of decimal pixel value, I implement a new class named fPixel(in `fPixel.h` and `fPixel.cpp`)
for storing and calculating `double` value pixels.

Also, as I use for loop condition to choose the pixels required for calculation. I don't need to extend the image here.
On the other hand, a general normalization is a must.

>In my code, I use the variable `solution` to control the filter.

### Scale

With three different filters, I scale checkerboard.bmp to different size:

size|300*512 | 512*300 | 300*300 | 800*800 | 
 :--:|:-:|:-:|:-:|:-:|
NN|<img src="../img/scale01.bmp" /> |<img src="../img/scale02.bmp" />|<img src="../img/scale03.bmp" />|<img src="../img/scale04.bmp" />|
Hat|<img src="../img/scale11.bmp" /> |<img src="../img/scale12.bmp" />|<img src="../img/scale13.bmp" />|<img src="../img/scale14.bmp" />|
Mitchell|<img src="../img/scale21.bmp" /> |<img src="../img/scale22.bmp" />|<img src="../img/scale23.bmp" />|<img src="../img/scale24.bmp" />|

### Shift

With three different filters, I shift checkerboard.bmp:

(tx,ty)| (35.2,35.2) | (35.3,-35.3) | (-35.5,35.5) | (-35.7,-35.7) | 
 :--:|:-:|:-:|:-:|:-:|
NN|<img src="../img/shift01.bmp" /> |<img src="../img/shift02.bmp" />|<img src="../img/shift03.bmp" />|<img src="../img/shift04.bmp" />|
Hat|<img src="../img/shift11.bmp" /> |<img src="../img/shift12.bmp" />|<img src="../img/shift13.bmp" />|<img src="../img/shift14.bmp" />|
Mitchell|<img src="../img/shift21.bmp" /> |<img src="../img/shift22.bmp" />|<img src="../img/shift23.bmp" />|<img src="../img/shift24.bmp" />|

Also I implement a QT widget for illustrating shift process.
Unfortunately, the Shift processing is not fast enough for an online demonstration. 
I have to shift the image in advance, and save them for QT to load.
In order to show non-integer shift, I set shift in range -10 to 10 with an increment of 0.2.

![](../img/shift.gif) 


 



